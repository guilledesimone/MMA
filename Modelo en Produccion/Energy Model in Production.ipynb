{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model in Production for Wind Power Predictions - PE La Castellana\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset que se va a trabajar corresponde al Parque Eólico La Castellana (localizado en Bahia Blanca)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.mode.copy_on_write = True \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error#, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "\n",
    "\n",
    "# Utilities\n",
    "import os\n",
    "import pickle\n",
    "import requests as req\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "# LightGBM model\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = 'dist' # Should be clean before the execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de dataset de Históricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/guilledesimone/MMA-Tesis/refs/heads/main/Datos/ds_histo_02022019-13062024.csv'\n",
    "#path = 'D:\\\\Documents\\\\MMA\\\\1.0 Tesis\\\\Datos\\\\ds_histo_02022019-13062024.csv' \n",
    "\n",
    "df_histo_full = pd.read_csv(path, decimal=',', parse_dates=['FechaHora'], \n",
    "                 date_format='%Y-%m-%d %H:%M:%S', delimiter=';', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where EnergiaSMEC is NaN\n",
    "df_histo_full.dropna(subset=['EnergiaSMEC'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de dataset de Forecast & Actual para evaluar performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/guilledesimone/MMA-Tesis/refs/heads/main/Datos/ds_fc_actual_02062024-11062024.csv'\n",
    "\n",
    "#path = 'D:\\\\Documents\\\\MMA\\\\1.0 Tesis\\\\Datos\\\\ds_fc_actual_02062024-11062024.csv' #lote 1\n",
    "#path = 'D:\\\\Documents\\\\MMA\\\\1.0 Tesis\\\\Datos\\\\ds_fc_actual_17062024-26062024.csv' #lote 2\n",
    "\n",
    "\n",
    "df_fc_actual = pd.read_csv(path, decimal=',', parse_dates=['FechaHora'], \n",
    "                 date_format='%Y-%m-%d %H:%M:%S', delimiter=';', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El forecast de aero_disp lo estimo en base al valor medio\n",
    "\n",
    "# Filter the subset where AerosDisp is not null\n",
    "filtered_df = df_fc_actual.dropna(subset=['aeros_disp'])\n",
    "\n",
    "# Calculate the mean of aero_disp \n",
    "mean_aeros_disp = filtered_df.tail(12)['aeros_disp'].mean()\n",
    "\n",
    "df_fc_actual['aeros_disp'] = mean_aeros_disp.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selección de variables relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired column order\n",
    "main_features = ['FechaHora','EnergiaSMEC','aeros_disp','ws100_avg', 'dir100_avg', 'temp_avg','energia_fc_cammesa'] #promedio de fuentes de ecwmf y gfs\n",
    "#main_features = ['FechaHora','EnergiaSMEC','aeros_disp','ws100_ecmwf', 'dir100_ecmwf', 'temp_ecmwf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fc_actual = df_fc_actual[main_features[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fc_actual.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparación de datos historico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the minimum FechaHora\n",
    "start_date = df_fc_actual['FechaHora'].min()\n",
    "\n",
    "# Exclude data with FechaHora >= start_date, because this is the initial date for the forecast \n",
    "df_histo_full = df_histo_full[df_histo_full['FechaHora'] < start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main the DataFrame columns\n",
    "df_histo = df_histo_full[main_features[:-1]]\n",
    "\n",
    "# Set FechaHora as Index\n",
    "#df_histo.set_index('FechaHora', inplace=True)\n",
    "\n",
    "#df_histo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Division en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start date for the train and test sets\n",
    "train_start_dt = df_histo['FechaHora'].min()\n",
    "test_start_dt = df_histo['FechaHora'].max() - pd.Timedelta(days=365)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (37966, 6)\n",
      "Test data shape:  (8761, 7)\n"
     ]
    }
   ],
   "source": [
    "# Create train set containing only the model features\n",
    "df_train = df_histo[\n",
    "(df_histo['FechaHora'] >= train_start_dt)\n",
    "& (df_histo['FechaHora'] < test_start_dt)].copy()\n",
    "\n",
    "# Create test set containing only the model features\n",
    "df_test = df_histo_full[df_histo_full['FechaHora'] >= test_start_dt][main_features].copy()\n",
    "\n",
    "print('Training data shape: ', df_train.shape)\n",
    "print('Test data shape: ', df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparación de dataset forecast - exogenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exog_features = [feature for feature in main_features if feature != 'EnergiaSMEC'and feature != 'energia_fc_cammesa']\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "df_fc_actual_exog = df_fc_actual[exog_features]\n",
    "# Set FechaHora as Index\n",
    "df_fc_actual_exog.set_index('FechaHora', inplace=True)\n",
    "\n",
    "#df_fc_actual_exog.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.set_index('FechaHora', inplace=True)\n",
    "df_train.set_index('FechaHora', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "x_train, y_train = df_train.drop(columns=['EnergiaSMEC']), df_train['EnergiaSMEC'].values\n",
    "x_test, y_test = df_test.drop(columns=['EnergiaSMEC','energia_fc_cammesa']), df_test['EnergiaSMEC'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "x_train, y_train = df_train.drop(columns=['EnergiaSMEC']), df_train['EnergiaSMEC'].values\n",
    "x_test, y_test = df_test.drop(columns=['EnergiaSMEC','energia_fc_cammesa']), df_test['EnergiaSMEC'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgbm(x_train: pd.DataFrame, y_train: np.ndarray) -> LGBMRegressor:\n",
    "    \"\"\"\n",
    "        Fits a LigthGBM model, saves the model and returns it.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "    'num_leaves': 30,\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 8,\n",
    "    'min_child_samples': 200,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.70,\n",
    "    'colsample_bytree': 0.75\n",
    "    }\n",
    "\n",
    "    # Initialize the model\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    \n",
    "    # Parameter grid for RandomizedSearchCV\n",
    "    param_grid = {\n",
    "        'num_leaves': [20, 30, 40, 50],\n",
    "        'n_estimators': [50,70,100, 200, 400, 600],\n",
    "        'max_depth': [6, 8, 10, 12],\n",
    "        'min_child_samples': [20, 50, 100, 200, 400, 600],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
    "        'subsample': [0.5, 0.7, 0.8, 0.9],\n",
    "        'colsample_bytree': [0.6, 0.75, 0.8, 0.9, 1]\n",
    "    }\n",
    "    \n",
    "    # Set up TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    # Set up RandomizedSearchCV with TimeSeriesSplit\n",
    "    random_search = RandomizedSearchCV(\n",
    "        model, param_distributions=param_grid, n_iter=25, cv=tscv, verbose=1, n_jobs=-1,\n",
    "        random_state=14, scoring='neg_mean_squared_error'\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    random_search.fit(x_train, y_train)\n",
    "       \n",
    "    # Get the best model\n",
    "    best_model = random_search.best_estimator_\n",
    "    \n",
    "    file_name = 'model.pkl'\n",
    "    with open(os.path.join(FOLDER, file_name), 'wb') as f:\n",
    "        pickle.dump(best_model, f)     \n",
    "\n",
    "    print('Model saved')\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 37966, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 47.909617\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "model = fit_lgbm(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: LGBMRegressor(colsample_bytree=0.9, max_depth=8, min_child_samples=100,\n",
      "              n_estimators=50, num_leaves=30, subsample=0.5)\n",
      "MAE: 10.923722234236603\n",
      "RMSE: 16.194633689456477\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mae_t = mean_absolute_error(y_test, y_pred)\n",
    "mse_t = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rmse_t = np.sqrt(mse_t)\n",
    "print(f'Best parameters found: {model}')\n",
    "print(f'MAE: {mae_t}')\n",
    "print(f'RMSE: {rmse_t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción de Energia en dataset de TEST (último año) con LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_test.index.name != 'FechaHora':\n",
    "    df_test.set_index('FechaHora', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date: 2023-06-02 23:00:00 | End date: 2024-06-01 23:00:00\n"
     ]
    }
   ],
   "source": [
    "# Get the minimum and maximum FechaHora\n",
    "start_test_date = df_test.index.min()\n",
    "end_test_date = df_test.index.max()\n",
    "print(f\"Start date: {start_test_date} | End date: {end_test_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_exog = df_test[exog_features[1:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "pred_test_energia_lgb = model.predict(df_test_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the predictions\n",
    "df_pred_test_energia_lgb = pd.DataFrame({\n",
    "    'FechaHora': df_test_exog.index,\n",
    "    'pred_energia_lgb': pred_test_energia_lgb\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FechaHora</th>\n",
       "      <th>pred_energia_lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-02 23:00:00</td>\n",
       "      <td>15.681673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-03 00:00:00</td>\n",
       "      <td>18.151282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-03 01:00:00</td>\n",
       "      <td>28.366471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-03 02:00:00</td>\n",
       "      <td>24.321430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-03 03:00:00</td>\n",
       "      <td>33.980329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            FechaHora  pred_energia_lgb\n",
       "0 2023-06-02 23:00:00         15.681673\n",
       "1 2023-06-03 00:00:00         18.151282\n",
       "2 2023-06-03 01:00:00         28.366471\n",
       "3 2023-06-03 02:00:00         24.321430\n",
       "4 2023-06-03 03:00:00         33.980329"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_test_energia_lgb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción de Energia a 10 dias con LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fc_actual_exog.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date: 2024-06-02 00:00:00 | End date: 2024-06-11 21:00:00\n"
     ]
    }
   ],
   "source": [
    "# Get the minimum and maximum FechaHora\n",
    "start_date_10d = df_fc_actual_exog['FechaHora'].min()\n",
    "end_date_10d = df_fc_actual_exog['FechaHora'].max()\n",
    "print(f\"Start date: {start_date_10d} | End date: {end_date_10d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fc_actual_exog['FechaHora'] = pd.to_datetime(df_fc_actual_exog['FechaHora'])\n",
    "df_fc_actual_exog.set_index('FechaHora', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "pred_10d_energia_lgb = model.predict(df_fc_actual_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the predictions\n",
    "df_pred_10d_energia_lgb = pd.DataFrame({\n",
    "    'FechaHora': df_fc_actual_exog.index,\n",
    "    'pred_energia_lgb': pred_10d_energia_lgb\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FechaHora</th>\n",
       "      <th>pred_energia_lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-06-02 00:00:00</td>\n",
       "      <td>10.649182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-06-02 01:00:00</td>\n",
       "      <td>12.187967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-06-02 02:00:00</td>\n",
       "      <td>15.378987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-02 03:00:00</td>\n",
       "      <td>33.362576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-06-02 04:00:00</td>\n",
       "      <td>34.581394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            FechaHora  pred_energia_lgb\n",
       "0 2024-06-02 00:00:00         10.649182\n",
       "1 2024-06-02 01:00:00         12.187967\n",
       "2 2024-06-02 02:00:00         15.378987\n",
       "3 2024-06-02 03:00:00         33.362576\n",
       "4 2024-06-02 04:00:00         34.581394"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_10d_energia_lgb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Comandos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH'] += ';D:\\\\Program Files\\\\Docker\\\\Docker\\\\resources\\\\bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comandos\n",
    "#!docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY   TAG       IMAGE ID   CREATED   SIZE\n"
     ]
    }
   ],
   "source": [
    "# O !docker image ls\n",
    "#!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conteiners corridos hasta el momento:\n",
    "#!docker container ls --all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para correr la imagen:\n",
    "\n",
    "# Terminal\n",
    "#!docker run --interactive --tty ubuntu bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correr un servicio foreground (ejecutar en primer plano) para entorno de desarrollo:\n",
    "\n",
    "# Terminal\n",
    "#!docker run --publish 80:80 flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correr un servicio detached (ejecutar en modo desacoplado) para entorno productivo:\n",
    "\n",
    "#!docker run --detach --publish 80:80 flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para ver que servicios estan corriendo:\n",
    "\n",
    "#`uname -a` nos va a mostrar que container y host están compartiendo el kernel\n",
    "\n",
    "#!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para ver los logs:\n",
    "\n",
    "#!docker logs 7f98c7a7f655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detener el contenedor:\n",
    "\n",
    "#!docker stop 7f98c7a7f655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para nombrar el container:\n",
    "\n",
    "#!docker run --detach --publish 80:80 --name webserver nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listar contenedores:\n",
    "\n",
    "#!docker container ls --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminar un contenedor\n",
    "\n",
    "#!docker rm webserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cuanto recursos ocupa el contenedor\n",
    "\n",
    "#!docker stats --no-stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construccion de la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flask\n",
      "pandas\n",
      "requests\n",
      "scikit-learn\n",
      "lightgbm\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Archivos de requerimientos\n",
    "!type requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intelacion en el ambiente\n",
    "\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Imagen padre desde la que vamos a heredar. \n",
      "FROM python:3.11\n",
      "\n",
      "# Directorio adentro del container en donde vamos a trabajar\n",
      "WORKDIR /app_energypred\n",
      "\n",
      "# Contexto: Copia todo el contenido de este directorio adentro del container en la carpeta /app\n",
      "COPY . /app_energypred\n",
      "\n",
      "# Correr un comando, en este caso para instalar las dependencias en requirements.txt\n",
      "RUN pip install -r requirements.txt\n",
      "\n",
      "# Abre el puerto 5000 del container\n",
      "EXPOSE 5000\n",
      "\n",
      "# Cuando el container se lance va a ejecutar este comando\n",
      "CMD [\"python\", \"energy_app.py\"]\n"
     ]
    }
   ],
   "source": [
    "!type Dockerfile_energypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#0 building with \"desktop-linux\" instance using docker driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile_energypred\n",
      "#1 transferring dockerfile: 580B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load metadata for docker.io/library/python:3.11\n",
      "#2 ...\n",
      "\n",
      "#3 [auth] library/python:pull token for registry-1.docker.io\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#2 [internal] load metadata for docker.io/library/python:3.11\n",
      "#2 DONE 2.3s\n",
      "\n",
      "#4 [internal] load .dockerignore\n",
      "#4 transferring context: 2B done\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [1/4] FROM docker.io/library/python:3.11@sha256:706d1233c61a31507c4f8939cfd6a924610b51174c095f33e2c537fb904a1e76\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [internal] load build context\n",
      "#6 transferring context: 162.37kB 0.0s done\n",
      "#6 DONE 0.0s\n",
      "\n",
      "#7 [2/4] WORKDIR /app_energypred\n",
      "#7 CACHED\n",
      "\n",
      "#8 [3/4] COPY . /app_energypred\n",
      "#8 DONE 0.1s\n",
      "\n",
      "#9 [4/4] RUN pip install -r requirements.txt\n",
      "#9 2.899 Collecting Flask (from -r requirements.txt (line 1))\n",
      "#9 3.741   Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "#9 3.959 Collecting pandas (from -r requirements.txt (line 2))\n",
      "#9 3.980   Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "#9 4.024      â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 89.9/89.9 kB 1.9 MB/s eta 0:00:00\n",
      "#9 4.113 Collecting requests (from -r requirements.txt (line 3))\n",
      "#9 4.133   Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "#9 4.281 Collecting scikit-learn (from -r requirements.txt (line 4))\n",
      "#9 4.298   Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "#9 4.516 Collecting lightgbm (from -r requirements.txt (line 5))\n",
      "#9 4.533   Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
      "#9 4.622 Collecting Werkzeug>=3.1 (from Flask->-r requirements.txt (line 1))\n",
      "#9 4.644   Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "#9 4.706 Collecting Jinja2>=3.1.2 (from Flask->-r requirements.txt (line 1))\n",
      "#9 4.726   Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "#9 4.927 Collecting itsdangerous>=2.2 (from Flask->-r requirements.txt (line 1))\n",
      "#9 4.943   Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "#9 5.005 Collecting click>=8.1.3 (from Flask->-r requirements.txt (line 1))\n",
      "#9 5.022   Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "#9 5.085 Collecting blinker>=1.9 (from Flask->-r requirements.txt (line 1))\n",
      "#9 5.101   Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "#9 5.504 Collecting numpy>=1.23.2 (from pandas->-r requirements.txt (line 2))\n",
      "#9 5.527   Downloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "#9 5.545      â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 62.0/62.0 kB 3.7 MB/s eta 0:00:00\n",
      "#9 5.608 Collecting python-dateutil>=2.8.2 (from pandas->-r requirements.txt (line 2))\n",
      "#9 5.627   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "#9 5.732 Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 2))\n",
      "#9 5.751   Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "#9 5.815 Collecting tzdata>=2022.7 (from pandas->-r requirements.txt (line 2))\n",
      "#9 5.834   Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "#9 5.987 Collecting charset-normalizer<4,>=2 (from requests->-r requirements.txt (line 3))\n",
      "#9 6.007   Downloading charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "#9 6.083 Collecting idna<4,>=2.5 (from requests->-r requirements.txt (line 3))\n",
      "#9 6.105   Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "#9 6.208 Collecting urllib3<3,>=1.21.1 (from requests->-r requirements.txt (line 3))\n",
      "#9 6.228   Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "#9 6.293 Collecting certifi>=2017.4.17 (from requests->-r requirements.txt (line 3))\n",
      "#9 6.313   Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "#9 6.613 Collecting scipy>=1.6.0 (from scikit-learn->-r requirements.txt (line 4))\n",
      "#9 6.637   Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "#9 6.658      â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 60.8/60.8 kB 3.5 MB/s eta 0:00:00\n",
      "#9 6.731 Collecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 4))\n",
      "#9 6.983   Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "#9 7.036 Collecting threadpoolctl>=3.1.0 (from scikit-learn->-r requirements.txt (line 4))\n",
      "#9 7.058   Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "#9 7.225 Collecting MarkupSafe>=2.0 (from Jinja2>=3.1.2->Flask->-r requirements.txt (line 1))\n",
      "#9 7.246   Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "#9 7.319 Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2))\n",
      "#9 7.345   Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "#9 7.459 Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "#9 7.487    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 103.0/103.0 kB 4.0 MB/s eta 0:00:00\n",
      "#9 7.507 Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "#9 8.695    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 13.1/13.1 MB 10.6 MB/s eta 0:00:00\n",
      "#9 8.717 Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "#9 8.730    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 64.9/64.9 kB 5.1 MB/s eta 0:00:00\n",
      "#9 8.747 Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "#9 9.814    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 13.3/13.3 MB 12.5 MB/s eta 0:00:00\n",
      "#9 9.838 Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "#9 10.12    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 3.6/3.6 MB 12.5 MB/s eta 0:00:00\n",
      "#9 10.14 Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "#9 10.17 Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "#9 10.19    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 167.3/167.3 kB 7.8 MB/s eta 0:00:00\n",
      "#9 10.21 Downloading charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "#9 10.25    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 142.6/142.6 kB 4.5 MB/s eta 0:00:00\n",
      "#9 10.27 Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "#9 10.30    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 97.9/97.9 kB 3.9 MB/s eta 0:00:00\n",
      "#9 10.32 Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "#9 10.33    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 70.4/70.4 kB 4.6 MB/s eta 0:00:00\n",
      "#9 10.36 Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "#9 10.39 Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "#9 10.41    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 133.3/133.3 kB 5.9 MB/s eta 0:00:00\n",
      "#9 10.44 Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "#9 10.48    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 301.8/301.8 kB 7.4 MB/s eta 0:00:00\n",
      "#9 10.49 Downloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "#9 11.84    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 16.3/16.3 MB 11.5 MB/s eta 0:00:00\n",
      "#9 11.86 Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "#9 11.90    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 229.9/229.9 kB 7.1 MB/s eta 0:00:00\n",
      "#9 11.92 Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "#9 11.98    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 508.0/508.0 kB 8.8 MB/s eta 0:00:00\n",
      "#9 12.00 Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "#9 15.67    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 41.2/41.2 MB 10.6 MB/s eta 0:00:00\n",
      "#9 15.68 Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "#9 15.72 Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "#9 15.76    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 346.6/346.6 kB 9.7 MB/s eta 0:00:00\n",
      "#9 15.78 Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "#9 15.80    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 126.3/126.3 kB 7.3 MB/s eta 0:00:00\n",
      "#9 15.84 Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "#9 15.87    â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”� 224.5/224.5 kB 7.1 MB/s eta 0:00:00\n",
      "#9 15.89 Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "#9 15.92 Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "#9 16.50 Installing collected packages: pytz, urllib3, tzdata, threadpoolctl, six, numpy, MarkupSafe, joblib, itsdangerous, idna, click, charset-normalizer, certifi, blinker, Werkzeug, scipy, requests, python-dateutil, Jinja2, scikit-learn, pandas, lightgbm, Flask\n",
      "#9 30.10 Successfully installed Flask-3.1.0 Jinja2-3.1.4 MarkupSafe-3.0.2 Werkzeug-3.1.3 blinker-1.9.0 certifi-2024.8.30 charset-normalizer-3.4.0 click-8.1.7 idna-3.10 itsdangerous-2.2.0 joblib-1.4.2 lightgbm-4.5.0 numpy-2.1.3 pandas-2.2.3 python-dateutil-2.9.0.post0 pytz-2024.2 requests-2.32.3 scikit-learn-1.5.2 scipy-1.14.1 six-1.16.0 threadpoolctl-3.5.0 tzdata-2024.2 urllib3-2.2.3\n",
      "#9 30.10 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "#9 32.44 \n",
      "#9 32.44 [notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "#9 32.44 [notice] To update, run: pip install --upgrade pip\n",
      "#9 DONE 38.1s\n",
      "\n",
      "#10 exporting to image\n",
      "#10 exporting layers\n",
      "#10 exporting layers 3.1s done\n",
      "#10 writing image sha256:07ccde75533d3ada583f45dd1a89bf6dfc199413371e5ac5e721aaffbcf67103 done\n",
      "#10 naming to docker.io/library/energy_predictor done\n",
      "#10 DONE 3.2s\n"
     ]
    }
   ],
   "source": [
    "# Terminal\n",
    "!docker build --file Dockerfile_energypred --tag=energy_predictor . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY         TAG       IMAGE ID       CREATED         SIZE\n",
      "energy_predictor   latest    07ccde75533d   3 seconds ago   1.49GB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker stop energy_pred_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker rename webserver energy_pred_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34a1c6e358d587abe6ea5261d143e40ca59ebf17185be5d4bd84c554a8d1f2c9\n"
     ]
    }
   ],
   "source": [
    "# Terminal\n",
    "!docker run -d --name energy_pred_app --rm --publish 80:5000 energy_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   NAME              CPU %     MEM USAGE / LIMIT     MEM %     NET I/O     BLOCK I/O   PIDS\n",
      "34a1c6e358d5   energy_pred_app   280.50%   161.2MiB / 15.43GiB   1.02%     606B / 0B   0B / 0B     35\n"
     ]
    }
   ],
   "source": [
    "#cuanto recursos ocupa el contenedor\n",
    "!docker stats --no-stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para inspeccionar desde adentro el contenedor que esta corriendo\n",
    "#Terminal\n",
    "\n",
    "#!docker exec --interactive --tty energy_predictor bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publicacion de la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticating with existing credentials...\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "# Terminal\n",
    "!docker login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY         TAG       IMAGE ID       CREATED          SIZE\n",
      "energy_predictor   latest    07ccde75533d   11 seconds ago   1.49GB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag energy_predictor gdesimone/energy_predictor_app:v1.0\n",
    "!docker push gdesimone/energy_predictor_app:v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis-python-3.11",
   "language": "python",
   "name": "tesis-python-3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
